{"title":"Causality in observational data","markdown":{"yaml":{"title":"Causality in observational data","author":"Erdem Karaköylü","description":"Matching and propensity scores for causal inference","date":"2022-08-08","categories":["causality","propensity score","R"],"image":"run.jpg"},"headingText":"Matching","containsRefs":false,"markdown":"\n\n**Preamble**\n\nIn the real world, we often want to understand if something (a new medicine, a marketing campaign, a policy change) truly causes an outcome.  In ideal experiments (like Randomized Control Trials or RCTs), we can control all factors, making it easier to determine cause and effect.\n\nBut what if we only have observational data, where things weren't neatly controlled? Establishing a causal link becomes tricky.  There might be hidden factors, called confounders, that influence both the treatment and the outcome, making it hard to tell if the treatment is the real cause. This post explores ways to tackle this challenge.\n\n**Example: Does Exercise Cause Weight Loss?**\n\nImagine a study on the impact of a new exercise program on weight loss. Participants with higher fitness levels might be more likely to choose the program.  This becomes a confounder – fitness level influences both program participation and weight loss outcomes.  Propensity score matching can help – it pairs individuals with similar fitness levels but different program participation, isolating the program's true effect.\n\n**Using the Lalonde Dataset**\n\nTo illustrate how matching and propensity scores can help with causal analysis, I'll use a dataset from a study by [Lalonde (1986)](https://www.researchgate.net/publication/4900843_Evaluating_the_Econometric_Evaluations_of_Training_Programs_with_Experiment_Data) evaluating an employment and training program. The study aimed to understand if the program truly caused better employment outcomes. Let's load the data from the 'Matching' R library and take a closer look:\n\n```{r, warning=FALSE, message=FALSE}\nlibrary(MatchIt)\ndata(lalonde)\n```\nThe loaded data includes a number of covariates, an outcome variable and a treatment flag indicating whether the subject was part of the control or the treatment group. These variables are named and summarized in the table below.\n\n\n| Variable    | Summary                         |\n|-------------|---------------------------------|\n| age^1^      | in floating point years         |\n| race^1^     | One of Black, Hispanic, White   |\n| educ^1^     | years of schooling              |\n| married^1^  | Boolean for marital status      |\n| nodegree^1^ | Boolean for high school diploma |\n| re74^1^     | real earnings in 1974           |\n| re75^1^     | real earnings in 1975           |\n| re78^2^     | real earnings in 1978           |\n| treat^3^    | Boolean for treatment status    |\n\nFor convenience, I one-hot encode the race variable, and cast it in its new format along with the rest of the data in a new table that follows. Note that in the present subset of this data, only black and white subjects were available. I therefore do not include hispanic as a covariate in the analysis that follows. For convenience, I also change the outcome variable, $re78$ to the more meaningful name $outcome$.\n```{r}\nhispan<-as.numeric(lalonde$race=='hispan')\nblack<-as.numeric(lalonde$race=='black')\nwhite<-as.numeric(lalonde$race=='white')\nage<-lalonde$age\neduc<-lalonde$educ\nmarried<-lalonde$married\nnodegree<-lalonde$nodegree\nre74<-lalonde$re74\nre75<-lalonde$re75\ntreat<-lalonde$treat\noutcome<-lalonde$re78\nmydata<-cbind(age, educ, married, nodegree, black, white, hispan, \n              re74, re75, treat, outcome)\nmydata<-data.frame(mydata)\n```\nAll covariates are expected to be confounders. Thus it is important to evaluate whether the data is balanced between treatment and control groups; i.e. whether the covariates are similarly distributed between the two groups. If they are then the analysis can proceed. Otherwise, the data needs to be balanced. One way to balance data is to use *matching*; another will use something called propensity score. Next, I will illustrate both appraoches.\n\n### To match or not to match?\n\nA first step is whether the data on hand is appropriate for causal inferrence, in particular, whether it should be balanced. A commonly used metric to figure out whether balancing the data is required is Standardized Mean Difference ($SMD$), defined as the difference between group means divided by the pooled standard deviation, like so:\n\n$$\nSMD = \\frac{\\bar{X}_{treatment}-\\bar{X}_{control}}\n{\\sqrt{\\frac{s^2_{treatment}+s^2_{control}}{2}}}\n$$\nAn easy way to examine covariates is to cast them into what is know as a `Table 1`, after a common pattern in the biomedical research litterature to feature patient attributes in the first table of published papers. The *R* library tableone is commonly used for this purpose, with the added benefit that the SMD is given out of the box as shown below. Here the data is stratified by treatment group and only the covariates are tabulated.\n```{r}\nlibrary(tableone)\n\n# Make a vector of the variable names to be used\nxvars <-c(\"hispan\", \"black\", \"white\", \"age\", \"educ\", \"married\", \"nodegree\", \n              \"re74\", \"re75\")\n# load to a table 1\ntable1 <- CreateTableOne(vars=xvars, strata=\"treat\", data=mydata, test=FALSE)\n# show table, in particular display SMDs corresponding to each covariate. \nprint(table1, smd=TRUE)\n```\nNote that an alternative would be to conduct two-tailed t-tests to assess difference between group (treated and control) means for each covariate, and evaluate their corresponding p-value. This is however not without drawbacks; most importantly the resulting p-value will depend on the sample size. I therefore use $SMD$ in this post.\n\nBy convention, an $SMD$ greater than 0.1 suggest an imbalance with respect to the corresponding covariate. Here $SMD>0.1$ for all covariates except *education*. Treated subjects need each to be match via greedy matching to as close as possible a control subject. Matching between subjects is done on the basis of a distance metric indicating how separated they are in the covariate space. The specific metric used in this case is the **Mahalanobis distance**, which is a kind of standardized difference, computed as follows:\n$$d = \\sqrt{(X_i-X_j)^T C^{-1} (X_i-X_j) }$$\nwhere $X$ is a covariate, $i$ and $j$ are treated and control subjects, and $C$ is the covariance matrix\n\n```{r, warning=FALSE, message=FALSE}\nlibrary(Matching)\n# Below M=1 refers to pairwise matching. Even so if \"ties\" is left as TRUE (default)\n# multiple subjects within the tolerance threshold will all be matched. \n# In this case, e.g. not setting ties=TRUE yields 207 pairs, even though there are only # 185 treated subjects.\ngreedymatch<-Match(Tr=treat, M=1, X=mydata[xvars], ties=FALSE) \ngreedymatched<-mydata[unlist(greedymatch[c(\"index.treated\", \"index.control\")]), ]\n```\n\nI create another *Table 1* with the matched data check the SMDs.\n\n```{r}\nmatchedtab1<-CreateTableOne(vars=xvars, strata=\"treat\", data=greedymatched, test=FALSE)\nprint(matchedtab1, smd=TRUE)\n```\nGreedy pairwise matching yields, as expected, a reduced data set with 185 subjects in each group. This time all but the variable $re75$ have corresponding $SMD<0.1$. This is not entirely satisfactory and I will attempt to balance the data set using propensity scores next \n\n\n\n## Propensity score matching\n\nA propensity score denoted here $\\pi$ is defined as the probability that a subject $i$ received treatment  conditioned on the covariates $X$. I.e. $\\pi_i = P(T=1|X_i)$. A $\\pi_i=0.4$ means there's a 40% chance the corresponding subject will receive treatment. Covariates can increase or decrease the probability of receiving treatment. For example, if $X$, simplistically the only covariate, is a boolean variable for smoking and smokers are more likely to get a particular treatment then $P(T=1|X=1) \\gt P(T=1|X=0)$.  \n\nInterestingly, two subjects may have the same propensity score in spite of having different covariate values $X$, meaning they are equally likely to receive treatment. Thus reducing the data to a subset of subjects with the same $\\pi$ should balance the treated and control groups. In doing so a crucial assumption in causality, *ignorability* i.e. how a subject ended in one or the other group can be safely ignored.\nIn a randomized trial, the propensity score is known. In an observational study $\\pi$ is unknown. However because both $X$ and $T$ are collected, $\\pi$ can be estimated. For this I will fit a logistic regression, where the covariates are the input and the treatment variable is the output. Using this model I can get the predicted probability of treatment for each subject; i.e. the estimated $\\pi$.\n\n```{r}\npsmodel <- glm(treat~hispan+white+black+age+educ+married+\n                 nodegree+re74+re75,family=binomial(), data=mydata)\n```\nThe model fit is summarized below.\n\n```{r}\n# show fit summary\nsummary(psmodel)\n```\nNext I extract the propensity scores from the model object.\n```{r}\n# create propensity score\npscore<-psmodel$fitted.values\n```\nFinally, I use the MatchIt package to match subjects based on their propensity scores. Note that I set a seed for reproducibility, since matching randomizes data as a first step.\n```{r}\nset.seed(42)\nm.out<-matchit(treat~hispan+white+black+age+educ+married+\n                 nodegree+re74+re75, data=mydata, method=\"nearest\")\n```\n\nThe matching results are summarized below.\n```{r, message=FALSE}\n# summarize the matching outcome\nsummary(m.out)\n```\nThe above is more intuitively approached with some plotting as shown below.\n```{r, message=FALSE}\n# propensity score plots\nplot(m.out, type=\"hist\")\n```\nWhat I am looking for with the plot above is an improvement in the overlap between the distribution of propensity scores of matched control and treated groups, relative to the raw. There is obviously some improvement and I'll next check more concretely below how good the match is using SMD.\n```{r}\n# --> MATCHHING WITH & WITHOUT A CALIPER\n# Matching without a caliper\n# -> do greedy matching on logit (PS)\nset.seed(42)\npsmatch <- Match(Tr=mydata$treat, M=1, X=pscore, replace=FALSE)\nps_matched <- mydata[unlist(psmatch[c(\"index.treated\", \"index.control\")]), ]\nmatchedtab1_pscore <- CreateTableOne(vars=xvars, strata=\"treat\", data=ps_matched,\n                              test=FALSE)\nprint(matchedtab1_pscore, smd=TRUE)\n```\n\nThe table above shows marked improvement relative to the raw data. However, variables like *education* ($educ$) and *lack of high school degree* ($nodegree$) are marginal, while race-related variables ($hispan$, $black$, $white$) are still too high to safely avoid confounding. Overall it is quite a bit worse than the first attempt with greedy matching I did earlier using the Mahalanobis distance; though $re75$ is markedly better here.\n\n### Matching with a caliper\nOne way to try to improve on the matching is to use a caliper; i.e. a threshold (maximum) distance beyond which matching is not allowed. In practice, though somewhat arbitrarily, (1) the propensity scores are logit-transformed, (2) the standard deviation (SD) is calculated, and (3) the caliper is set to 0.2 times the SD, finally (4) the matching is performed subject to the caliper. A smaller caliper, which results in fewer but better pairs, trades more variance for less bias. The code below performs the aforementioned steps.\n\n```{r}\nset.seed(42)\nlogit_pscore = qlogis(pscore)\npsmatch_calip <-Match(Tr=mydata$treat, M=1, X=logit_pscore, replace=FALSE,\n                caliper=.2)\n# Note that the caliper is in St.Dev. units\nmatched_calip <- mydata[unlist(psmatch_calip[c(\"index.treated\", \"index.control\")]), ]\nmatchedtab1_calip <- CreateTableOne(vars=xvars, strata=\"treat\", data=matched_calip,\n                              test=FALSE)\nprint(matchedtab1_calip, smd=TRUE)\n# NOTE the smaller number of subjects for each treatment categories, resultng\n# from dropping previously matched subjects.\n```\nUsing the caliper has reduced the number of matched pairs down to 114. The high SMDs seen previously (without the caliper). However, for 1974 and 1975 real incomes $SMD > 0.1$. Thus I cannot be certain that the treatment is the only cause of the outcome. The table above suggests subjects' earning history is still a causal factor.\nWith this in mind, I next run an outcome analysis for all the approaches described previously. I do this at the end rather than after each outcome as a habit to prevent [p-hacking](https://en.wikipedia.org/wiki/Data_dredging).\n\n### Outcome analyses:\nTo analyze whether the difference in outcome between the treatment and the control groups are different, I run a paired t-test on the various matched data. But first a quick function to avoid some repetition.\n\n```{r}\n# function that accepts a matched data table and runs the paired t-test.\nrun_matched_ttest<- function(matched_table){\n  # get outcome data for both groups\n  treated_outcome <- matched_table$outcome[matched_table$treat==1]\n  control_outcome <- matched_table$outcome[matched_table$treat==0]\n  \n  # compute pairwise difference between both groups\n  diff_outcome <- treated_outcome - control_outcome\n  \n  # paired t-test\n  t.test(diff_outcome)\n}\n```\n\n$\\rightarrow$ Greedy Mahalanobis distance matching:\n```{r}\nrun_matched_ttest(greedymatched)\n```\n\n$\\rightarrow$ Propensity score matching (no caliper)\n```{r}\nrun_matched_ttest(ps_matched)\n```\n\n$\\rightarrow$ Propensity score matching with caliper\n```{r}\nrun_matched_ttest(matched_calip)\n```\nThus, from greedy Mahalanobis distance matching to propensity score matching with caliper, the statistical significance of the difference between groups does increase, with propensity score matching with caliper resulting the in the smallest p-value (0.20). This is still conventionally quite high, so that it is impossible to reject the null hypothesis, i.e. that there are no difference between the groups. Moreover, there is still a potential confounding problem in all cases. E.g. the SMD for real income in \\`74 and \\`75 remains above 0.1 suggesting I was not able to remove the confounding effect. Note though that I worked for a subset of the original data. Thus I would next re-run the analysis on the entire data set, which could lead to better matching. But that is a story for another day.\n\nPeaceful coding!\n\n<p align=\"center\">\n  <img src=\"coding_happy.png\" height=400>\n</p>\n<p align=\"center\">\n  [image source](https://cdn.discordapp.com/attachments/1008571061119483984/1105921557945131071/Intotheblue_under_water_photo_of_a_women_using_a_mac_laptop_a_p_2c7f5b5a-6e17-4f48-bd5c-669b7685d2d3.png)\n</p>\n","srcMarkdownNoYaml":"\n\n**Preamble**\n\nIn the real world, we often want to understand if something (a new medicine, a marketing campaign, a policy change) truly causes an outcome.  In ideal experiments (like Randomized Control Trials or RCTs), we can control all factors, making it easier to determine cause and effect.\n\nBut what if we only have observational data, where things weren't neatly controlled? Establishing a causal link becomes tricky.  There might be hidden factors, called confounders, that influence both the treatment and the outcome, making it hard to tell if the treatment is the real cause. This post explores ways to tackle this challenge.\n\n**Example: Does Exercise Cause Weight Loss?**\n\nImagine a study on the impact of a new exercise program on weight loss. Participants with higher fitness levels might be more likely to choose the program.  This becomes a confounder – fitness level influences both program participation and weight loss outcomes.  Propensity score matching can help – it pairs individuals with similar fitness levels but different program participation, isolating the program's true effect.\n\n**Using the Lalonde Dataset**\n\nTo illustrate how matching and propensity scores can help with causal analysis, I'll use a dataset from a study by [Lalonde (1986)](https://www.researchgate.net/publication/4900843_Evaluating_the_Econometric_Evaluations_of_Training_Programs_with_Experiment_Data) evaluating an employment and training program. The study aimed to understand if the program truly caused better employment outcomes. Let's load the data from the 'Matching' R library and take a closer look:\n\n```{r, warning=FALSE, message=FALSE}\nlibrary(MatchIt)\ndata(lalonde)\n```\nThe loaded data includes a number of covariates, an outcome variable and a treatment flag indicating whether the subject was part of the control or the treatment group. These variables are named and summarized in the table below.\n\n\n| Variable    | Summary                         |\n|-------------|---------------------------------|\n| age^1^      | in floating point years         |\n| race^1^     | One of Black, Hispanic, White   |\n| educ^1^     | years of schooling              |\n| married^1^  | Boolean for marital status      |\n| nodegree^1^ | Boolean for high school diploma |\n| re74^1^     | real earnings in 1974           |\n| re75^1^     | real earnings in 1975           |\n| re78^2^     | real earnings in 1978           |\n| treat^3^    | Boolean for treatment status    |\n\nFor convenience, I one-hot encode the race variable, and cast it in its new format along with the rest of the data in a new table that follows. Note that in the present subset of this data, only black and white subjects were available. I therefore do not include hispanic as a covariate in the analysis that follows. For convenience, I also change the outcome variable, $re78$ to the more meaningful name $outcome$.\n```{r}\nhispan<-as.numeric(lalonde$race=='hispan')\nblack<-as.numeric(lalonde$race=='black')\nwhite<-as.numeric(lalonde$race=='white')\nage<-lalonde$age\neduc<-lalonde$educ\nmarried<-lalonde$married\nnodegree<-lalonde$nodegree\nre74<-lalonde$re74\nre75<-lalonde$re75\ntreat<-lalonde$treat\noutcome<-lalonde$re78\nmydata<-cbind(age, educ, married, nodegree, black, white, hispan, \n              re74, re75, treat, outcome)\nmydata<-data.frame(mydata)\n```\nAll covariates are expected to be confounders. Thus it is important to evaluate whether the data is balanced between treatment and control groups; i.e. whether the covariates are similarly distributed between the two groups. If they are then the analysis can proceed. Otherwise, the data needs to be balanced. One way to balance data is to use *matching*; another will use something called propensity score. Next, I will illustrate both appraoches.\n\n## Matching\n### To match or not to match?\n\nA first step is whether the data on hand is appropriate for causal inferrence, in particular, whether it should be balanced. A commonly used metric to figure out whether balancing the data is required is Standardized Mean Difference ($SMD$), defined as the difference between group means divided by the pooled standard deviation, like so:\n\n$$\nSMD = \\frac{\\bar{X}_{treatment}-\\bar{X}_{control}}\n{\\sqrt{\\frac{s^2_{treatment}+s^2_{control}}{2}}}\n$$\nAn easy way to examine covariates is to cast them into what is know as a `Table 1`, after a common pattern in the biomedical research litterature to feature patient attributes in the first table of published papers. The *R* library tableone is commonly used for this purpose, with the added benefit that the SMD is given out of the box as shown below. Here the data is stratified by treatment group and only the covariates are tabulated.\n```{r}\nlibrary(tableone)\n\n# Make a vector of the variable names to be used\nxvars <-c(\"hispan\", \"black\", \"white\", \"age\", \"educ\", \"married\", \"nodegree\", \n              \"re74\", \"re75\")\n# load to a table 1\ntable1 <- CreateTableOne(vars=xvars, strata=\"treat\", data=mydata, test=FALSE)\n# show table, in particular display SMDs corresponding to each covariate. \nprint(table1, smd=TRUE)\n```\nNote that an alternative would be to conduct two-tailed t-tests to assess difference between group (treated and control) means for each covariate, and evaluate their corresponding p-value. This is however not without drawbacks; most importantly the resulting p-value will depend on the sample size. I therefore use $SMD$ in this post.\n\nBy convention, an $SMD$ greater than 0.1 suggest an imbalance with respect to the corresponding covariate. Here $SMD>0.1$ for all covariates except *education*. Treated subjects need each to be match via greedy matching to as close as possible a control subject. Matching between subjects is done on the basis of a distance metric indicating how separated they are in the covariate space. The specific metric used in this case is the **Mahalanobis distance**, which is a kind of standardized difference, computed as follows:\n$$d = \\sqrt{(X_i-X_j)^T C^{-1} (X_i-X_j) }$$\nwhere $X$ is a covariate, $i$ and $j$ are treated and control subjects, and $C$ is the covariance matrix\n\n```{r, warning=FALSE, message=FALSE}\nlibrary(Matching)\n# Below M=1 refers to pairwise matching. Even so if \"ties\" is left as TRUE (default)\n# multiple subjects within the tolerance threshold will all be matched. \n# In this case, e.g. not setting ties=TRUE yields 207 pairs, even though there are only # 185 treated subjects.\ngreedymatch<-Match(Tr=treat, M=1, X=mydata[xvars], ties=FALSE) \ngreedymatched<-mydata[unlist(greedymatch[c(\"index.treated\", \"index.control\")]), ]\n```\n\nI create another *Table 1* with the matched data check the SMDs.\n\n```{r}\nmatchedtab1<-CreateTableOne(vars=xvars, strata=\"treat\", data=greedymatched, test=FALSE)\nprint(matchedtab1, smd=TRUE)\n```\nGreedy pairwise matching yields, as expected, a reduced data set with 185 subjects in each group. This time all but the variable $re75$ have corresponding $SMD<0.1$. This is not entirely satisfactory and I will attempt to balance the data set using propensity scores next \n\n\n\n## Propensity score matching\n\nA propensity score denoted here $\\pi$ is defined as the probability that a subject $i$ received treatment  conditioned on the covariates $X$. I.e. $\\pi_i = P(T=1|X_i)$. A $\\pi_i=0.4$ means there's a 40% chance the corresponding subject will receive treatment. Covariates can increase or decrease the probability of receiving treatment. For example, if $X$, simplistically the only covariate, is a boolean variable for smoking and smokers are more likely to get a particular treatment then $P(T=1|X=1) \\gt P(T=1|X=0)$.  \n\nInterestingly, two subjects may have the same propensity score in spite of having different covariate values $X$, meaning they are equally likely to receive treatment. Thus reducing the data to a subset of subjects with the same $\\pi$ should balance the treated and control groups. In doing so a crucial assumption in causality, *ignorability* i.e. how a subject ended in one or the other group can be safely ignored.\nIn a randomized trial, the propensity score is known. In an observational study $\\pi$ is unknown. However because both $X$ and $T$ are collected, $\\pi$ can be estimated. For this I will fit a logistic regression, where the covariates are the input and the treatment variable is the output. Using this model I can get the predicted probability of treatment for each subject; i.e. the estimated $\\pi$.\n\n```{r}\npsmodel <- glm(treat~hispan+white+black+age+educ+married+\n                 nodegree+re74+re75,family=binomial(), data=mydata)\n```\nThe model fit is summarized below.\n\n```{r}\n# show fit summary\nsummary(psmodel)\n```\nNext I extract the propensity scores from the model object.\n```{r}\n# create propensity score\npscore<-psmodel$fitted.values\n```\nFinally, I use the MatchIt package to match subjects based on their propensity scores. Note that I set a seed for reproducibility, since matching randomizes data as a first step.\n```{r}\nset.seed(42)\nm.out<-matchit(treat~hispan+white+black+age+educ+married+\n                 nodegree+re74+re75, data=mydata, method=\"nearest\")\n```\n\nThe matching results are summarized below.\n```{r, message=FALSE}\n# summarize the matching outcome\nsummary(m.out)\n```\nThe above is more intuitively approached with some plotting as shown below.\n```{r, message=FALSE}\n# propensity score plots\nplot(m.out, type=\"hist\")\n```\nWhat I am looking for with the plot above is an improvement in the overlap between the distribution of propensity scores of matched control and treated groups, relative to the raw. There is obviously some improvement and I'll next check more concretely below how good the match is using SMD.\n```{r}\n# --> MATCHHING WITH & WITHOUT A CALIPER\n# Matching without a caliper\n# -> do greedy matching on logit (PS)\nset.seed(42)\npsmatch <- Match(Tr=mydata$treat, M=1, X=pscore, replace=FALSE)\nps_matched <- mydata[unlist(psmatch[c(\"index.treated\", \"index.control\")]), ]\nmatchedtab1_pscore <- CreateTableOne(vars=xvars, strata=\"treat\", data=ps_matched,\n                              test=FALSE)\nprint(matchedtab1_pscore, smd=TRUE)\n```\n\nThe table above shows marked improvement relative to the raw data. However, variables like *education* ($educ$) and *lack of high school degree* ($nodegree$) are marginal, while race-related variables ($hispan$, $black$, $white$) are still too high to safely avoid confounding. Overall it is quite a bit worse than the first attempt with greedy matching I did earlier using the Mahalanobis distance; though $re75$ is markedly better here.\n\n### Matching with a caliper\nOne way to try to improve on the matching is to use a caliper; i.e. a threshold (maximum) distance beyond which matching is not allowed. In practice, though somewhat arbitrarily, (1) the propensity scores are logit-transformed, (2) the standard deviation (SD) is calculated, and (3) the caliper is set to 0.2 times the SD, finally (4) the matching is performed subject to the caliper. A smaller caliper, which results in fewer but better pairs, trades more variance for less bias. The code below performs the aforementioned steps.\n\n```{r}\nset.seed(42)\nlogit_pscore = qlogis(pscore)\npsmatch_calip <-Match(Tr=mydata$treat, M=1, X=logit_pscore, replace=FALSE,\n                caliper=.2)\n# Note that the caliper is in St.Dev. units\nmatched_calip <- mydata[unlist(psmatch_calip[c(\"index.treated\", \"index.control\")]), ]\nmatchedtab1_calip <- CreateTableOne(vars=xvars, strata=\"treat\", data=matched_calip,\n                              test=FALSE)\nprint(matchedtab1_calip, smd=TRUE)\n# NOTE the smaller number of subjects for each treatment categories, resultng\n# from dropping previously matched subjects.\n```\nUsing the caliper has reduced the number of matched pairs down to 114. The high SMDs seen previously (without the caliper). However, for 1974 and 1975 real incomes $SMD > 0.1$. Thus I cannot be certain that the treatment is the only cause of the outcome. The table above suggests subjects' earning history is still a causal factor.\nWith this in mind, I next run an outcome analysis for all the approaches described previously. I do this at the end rather than after each outcome as a habit to prevent [p-hacking](https://en.wikipedia.org/wiki/Data_dredging).\n\n### Outcome analyses:\nTo analyze whether the difference in outcome between the treatment and the control groups are different, I run a paired t-test on the various matched data. But first a quick function to avoid some repetition.\n\n```{r}\n# function that accepts a matched data table and runs the paired t-test.\nrun_matched_ttest<- function(matched_table){\n  # get outcome data for both groups\n  treated_outcome <- matched_table$outcome[matched_table$treat==1]\n  control_outcome <- matched_table$outcome[matched_table$treat==0]\n  \n  # compute pairwise difference between both groups\n  diff_outcome <- treated_outcome - control_outcome\n  \n  # paired t-test\n  t.test(diff_outcome)\n}\n```\n\n$\\rightarrow$ Greedy Mahalanobis distance matching:\n```{r}\nrun_matched_ttest(greedymatched)\n```\n\n$\\rightarrow$ Propensity score matching (no caliper)\n```{r}\nrun_matched_ttest(ps_matched)\n```\n\n$\\rightarrow$ Propensity score matching with caliper\n```{r}\nrun_matched_ttest(matched_calip)\n```\nThus, from greedy Mahalanobis distance matching to propensity score matching with caliper, the statistical significance of the difference between groups does increase, with propensity score matching with caliper resulting the in the smallest p-value (0.20). This is still conventionally quite high, so that it is impossible to reject the null hypothesis, i.e. that there are no difference between the groups. Moreover, there is still a potential confounding problem in all cases. E.g. the SMD for real income in \\`74 and \\`75 remains above 0.1 suggesting I was not able to remove the confounding effect. Note though that I worked for a subset of the original data. Thus I would next re-run the analysis on the entire data set, which could lead to better matching. But that is a story for another day.\n\nPeaceful coding!\n\n<p align=\"center\">\n  <img src=\"coding_happy.png\" height=400>\n</p>\n<p align=\"center\">\n  [image source](https://cdn.discordapp.com/attachments/1008571061119483984/1105921557945131071/Intotheblue_under_water_photo_of_a_women_using_a_mac_laptop_a_p_2c7f5b5a-6e17-4f48-bd5c-669b7685d2d3.png)\n</p>\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.42","theme":"darkly","title":"Causality in observational data","author":"Erdem Karaköylü","description":"Matching and propensity scores for causal inference","date":"2022-08-08","categories":["causality","propensity score","R"],"image":"run.jpg"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}